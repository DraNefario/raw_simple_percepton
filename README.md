# raw_simple_percepton

While studying artificial intelligence and neural networks, I became curious not just about how to use them, but how they were built from the ground up.

With help from ChatGPT, I deepened my understanding of neural networks starting from the fundamentals:

What a neural network really is

Its historical origin and core mathematics

The logic of the AND gate using weights and thresholds

And finally, the Perceptron â€” the first model capable of learning through supervised training.

Fascinated by how the perceptron works, I decided to implement one myself using only basic algebra and logic, without relying on any high-level libraries.

This repository contains that raw, minimal implementation of a simple perceptron, built for educational purposes and to reinforce my understanding of the foundations of machine learning.

# About this project
This repository contains a raw, minimal implementation of a simple perceptron in Python. It was built entirely from scratch to reinforce my foundational understanding of machine learning and artificial neural networks.

 Trains on binary vectors

 Learns using the perceptron update rule

 Adjusts weights and bias via error correction

 No external libraries used, pure Python logic

Purpose

  Educational only. This project is not optimized for performance or scalability, it's meant to demystify how neural networks actually work under the hood.




 
